{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b04bb4f",
   "metadata": {},
   "source": [
    "# GeoCroissant CMIP6 Dataset Mockup\n",
    "\n",
    "This notebook demonstrates how to use the **GeoCroissant** library to discover, interrogate, and load CMIP6 environmental datasets for machine learning applications.\n",
    "\n",
    "**Key Features Demonstrated:**\n",
    "- Dataset discovery and search\n",
    "- CMIP6 dataset loading with STAC integration\n",
    "- Data interrogation and filtering\n",
    "- PyTorch Dataset creation for ML training\n",
    "- Visualization of geospatial climate data\n",
    "\n",
    "> **Note:** This is a mockup demonstration. The actual `croissant` library and extensions shown here are conceptual and not yet implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68e5a32",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "First, let's import all the necessary libraries for working with geospatial environmental datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c979786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All libraries imported successfully!\n",
      "Croissant version: 1.2.3\n",
      "PyTorch version: 2.1.0\n",
      "Xarray version: 2023.10.1\n",
      "Cartopy version: 0.22.0\n",
      "STAC Client version: 0.7.0\n"
     ]
    }
   ],
   "source": [
    "# Import libraries from the external mock module\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add current directory to Python path to find mymock.py\n",
    "current_dir = os.path.dirname(os.path.abspath('.'))\n",
    "if current_dir not in sys.path:\n",
    "    sys.path.insert(0, current_dir)\n",
    "\n",
    "# Import from our mock module\n",
    "from mymock import (\n",
    "    croissant, torch, xr, GeoCroissant, STACIntegration, DataLoader, Dataset,\n",
    "    torch_nn as nn, matplotlib_pyplot as plt, cartopy_crs as ccrs, \n",
    "    cartopy_feature as cfeature, pystac_client as Client\n",
    ")\n",
    "\n",
    "# Standard libraries (these are real)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"Croissant version: {croissant.__version__}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Xarray version: {xr.__version__}\")\n",
    "print(f\"Cartopy version: 0.22.0\")\n",
    "print(f\"STAC Client version: 0.7.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba47cb2",
   "metadata": {},
   "source": [
    "## 2. Discover Available Datasets\n",
    "\n",
    "Use GeoCroissant to search for available environmental datasets in various repositories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59dbb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 climate datasets:\n",
      "1. CMIP6_Global_Climate_Projections\n",
      "   Description: Multi-model ensemble of global climate projections from CMIP6\n",
      "   Provider: ESGF Data Nodes\n",
      "   Variables: temperature, precipitation, pressure...\n",
      "   Spatial Resolution: 1.25¬∞ x 1.25¬∞\n",
      "   Temporal Resolution: monthly\n",
      "\n",
      "2. ERA5_Reanalysis_Global\n",
      "   Description: ECMWF ERA5 atmospheric reanalysis dataset\n",
      "   Provider: Copernicus Climate Data Store\n",
      "   Variables: temperature, wind, pressure...\n",
      "   Spatial Resolution: 0.25¬∞ x 0.25¬∞\n",
      "   Temporal Resolution: hourly\n",
      "\n",
      "3. MODIS_Land_Surface_Temperature\n",
      "   Description: MODIS satellite-derived land surface temperature\n",
      "   Provider: NASA EARTHDATA\n",
      "   Variables: land_surface_temperature, emissivity...\n",
      "   Spatial Resolution: 1km\n",
      "   Temporal Resolution: daily\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize GeoCroissant with multiple data sources\n",
    "geocat = GeoCroissant(provider=\"https://catalogue.ceda.ac.uk/croissant/\")\n",
    "\n",
    "# Search for climate datasets\n",
    "climate_datasets = geocat.search(\n",
    "    keywords=[\"climate\", \"CMIP6\", \"temperature\", \"precipitation\"],\n",
    "    spatial_coverage=\"global\",\n",
    "    temporal_range=(\"2015-01-01\", \"2100-12-31\")\n",
    ")\n",
    "\n",
    "print(f\"Found {len(climate_datasets)} climate datasets:\")\n",
    "for i, dataset in enumerate(climate_datasets[:5]):  # Show first 5\n",
    "    print(f\"{i+1}. {dataset.name}\")\n",
    "    print(f\"   Description: {dataset.description}\")\n",
    "    print(f\"   Provider: {dataset.provider}\")\n",
    "    print(f\"   Variables: {', '.join(dataset.variables[:3])}...\")\n",
    "    print(f\"   Spatial Resolution: {dataset.spatial_resolution}\")\n",
    "    print(f\"   Temporal Resolution: {dataset.temporal_resolution}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af95ebc",
   "metadata": {},
   "source": [
    "## 3. Load CMIP6 Dataset\n",
    "\n",
    "Load the specific CMIP6 dataset using the integrated STAC client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361a0534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CMIP6 dataset loaded successfully!\n",
      "Dataset ID: cmip6_global_climate\n",
      "Title: CMIP6 Global Climate Projections\n",
      "Description: Comprehensive climate model data from CMIP6 including temperature, precipitation, and atmospheric variables\n",
      "License: CC-BY-4.0\n",
      "Extent: {'bbox': [-180, -90, 180, 90]}\n",
      "Time Range: {'interval': [['2015-01-01', '2100-12-31']]}\n",
      "\n",
      "üìÅ STAC Catalog Structure:\n",
      "Collections: 3\n",
      "  - temperature: Surface Temperature\n",
      "    Items: 120\n",
      "    Variables: tas, tasmax, tasmin, pr, huss\n",
      "\n",
      "  - precipitation: Precipitation\n",
      "    Items: 120\n",
      "    Variables: pr, prc, prsn, prw, evspsbl\n",
      "\n",
      "  - atmospheric: Atmospheric Variables\n",
      "    Items: 120\n",
      "    Variables: psl, ua, va, zg, hus\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the CMIP6 dataset by name\n",
    "cmip6_dataset = geocat.load_dataset(\"CMIP6_Global_Climate_Projections\")\n",
    "\n",
    "# The dataset is loaded with STAC integration\n",
    "print(\"‚úÖ CMIP6 dataset loaded successfully!\")\n",
    "print(f\"Dataset ID: {cmip6_dataset.id}\")\n",
    "print(f\"Title: {cmip6_dataset.title}\")\n",
    "print(f\"Description: {cmip6_dataset.description}\")\n",
    "print(f\"License: {cmip6_dataset.license}\")\n",
    "print(f\"Extent: {cmip6_dataset.spatial_extent}\")\n",
    "print(f\"Time Range: {cmip6_dataset.temporal_extent}\")\n",
    "\n",
    "# Show STAC catalog structure\n",
    "print(f\"\\nüìÅ STAC Catalog Structure:\")\n",
    "print(f\"Collections: {len(cmip6_dataset.collections)}\")\n",
    "for collection in cmip6_dataset.collections[:3]:\n",
    "    print(f\"  - {collection.id}: {collection.title}\")\n",
    "    print(f\"    Items: {len(collection.items)}\")\n",
    "    print(f\"    Variables: {', '.join(collection.summaries.get('variables', [])[:5])}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10642f70",
   "metadata": {},
   "source": [
    "## 4. Interrogate Dataset Contents\n",
    "\n",
    "Use GeoCroissant's extensions to deeply explore the dataset structure and metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ce48016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Interrogating CMIP6 dataset contents...\n",
      "üìä Available Climate Models (5):\n",
      "  - CESM2: NCAR\n",
      "    Resolution: 0.9x1.25 deg\n",
      "    Experiments: 3\n",
      "\n",
      "  - GFDL-ESM4: NOAA-GFDL\n",
      "    Resolution: 0.5 deg\n",
      "    Experiments: 4\n",
      "\n",
      "  - UKESM1-0-LL: MOHC\n",
      "    Resolution: 1.25x1.875 deg\n",
      "    Experiments: 3\n",
      "\n",
      "  - IPSL-CM6A-LR: IPSL\n",
      "    Resolution: 1.27x2.5 deg\n",
      "    Experiments: 4\n",
      "\n",
      "  - MPI-ESM1-2-HR: MPI-M\n",
      "    Resolution: 0.94x0.94 deg\n",
      "    Experiments: 3\n",
      "\n",
      "üß™ Available Experiments (5):\n",
      "  - ssp126: Low emissions scenario\n",
      "    Activity: ScenarioMIP\n",
      "    Models: 12\n",
      "\n",
      "  - ssp245: Medium emissions scenario\n",
      "    Activity: ScenarioMIP\n",
      "    Models: 15\n",
      "\n",
      "  - ssp370: Medium-high emissions scenario\n",
      "    Activity: ScenarioMIP\n",
      "    Models: 8\n",
      "\n",
      "  - ssp585: High emissions scenario\n",
      "    Activity: ScenarioMIP\n",
      "    Models: 18\n",
      "\n",
      "  - historical: Historical simulation\n",
      "    Activity: CMIP\n",
      "    Models: 25\n",
      "\n",
      "üå°Ô∏è Available Variables (10):\n",
      "  - tas: Near-Surface Air Temperature\n",
      "    Units: K\n",
      "    Frequency: mon\n",
      "    Dimensions: ['time', 'lat', 'lon']\n",
      "\n",
      "  - pr: Precipitation\n",
      "    Units: kg m-2 s-1\n",
      "    Frequency: mon\n",
      "    Dimensions: ['time', 'lat', 'lon']\n",
      "\n",
      "  - psl: Sea Level Pressure\n",
      "    Units: Pa\n",
      "    Frequency: mon\n",
      "    Dimensions: ['time', 'lat', 'lon']\n",
      "\n",
      "  - ua: Eastward Near-Surface Wind\n",
      "    Units: m s-1\n",
      "    Frequency: mon\n",
      "    Dimensions: ['time', 'lat', 'lon']\n",
      "\n",
      "  - va: Northward Near-Surface Wind\n",
      "    Units: m s-1\n",
      "    Frequency: mon\n",
      "    Dimensions: ['time', 'lat', 'lon']\n",
      "\n",
      "  - huss: Near-Surface Specific Humidity\n",
      "    Units: 1\n",
      "    Frequency: mon\n",
      "    Dimensions: ['time', 'lat', 'lon']\n",
      "\n",
      "  - zg: Geopotential Height\n",
      "    Units: m\n",
      "    Frequency: mon\n",
      "    Dimensions: ['time', 'plev', 'lat', 'lon']\n",
      "\n",
      "  - evspsbl: Evaporation\n",
      "    Units: kg m-2 s-1\n",
      "    Frequency: mon\n",
      "    Dimensions: ['time', 'lat', 'lon']\n",
      "\n",
      "  - tasmax: Daily Maximum Near-Surface Air Temperature\n",
      "    Units: K\n",
      "    Frequency: day\n",
      "    Dimensions: ['time', 'lat', 'lon']\n",
      "\n",
      "  - tasmin: Daily Minimum Near-Surface Air Temperature\n",
      "    Units: K\n",
      "    Frequency: day\n",
      "    Dimensions: ['time', 'lat', 'lon']\n",
      "\n",
      "üîß Other Available Properties:\n",
      "Available props: models, experiments, variables, frequencies, realms, institutions, grids, time_ranges\n",
      "Use cmip6_dataset.get_props('property_name') to explore any of these:\n"
     ]
    }
   ],
   "source": [
    "# Use the generic interrogation API to explore the dataset\n",
    "print(\"üîç Interrogating CMIP6 dataset contents...\")\n",
    "\n",
    "# Get available climate models using generic props interface\n",
    "models = cmip6_dataset.get_props(\"models\")\n",
    "print(f\"üìä Available Climate Models ({len(models)}):\")\n",
    "for model in models[:8]:\n",
    "    print(f\"  - {model.name}: {model.institution}\")\n",
    "    print(f\"    Resolution: {model.nominal_resolution}\")\n",
    "    print(f\"    Experiments: {len(model.experiments)}\")\n",
    "    print()\n",
    "\n",
    "# Get available experiments\n",
    "experiments = cmip6_dataset.get_props(\"experiments\")\n",
    "print(f\"üß™ Available Experiments ({len(experiments)}):\")\n",
    "for exp in experiments[:5]:\n",
    "    print(f\"  - {exp.experiment_id}: {exp.description}\")\n",
    "    print(f\"    Activity: {exp.activity_id}\")\n",
    "    print(f\"    Models: {len(exp.participating_models)}\")\n",
    "    print()\n",
    "\n",
    "# Get available variables\n",
    "variables = cmip6_dataset.get_props(\"variables\")\n",
    "print(f\"üå°Ô∏è Available Variables ({len(variables)}):\")\n",
    "for var in variables[:10]:\n",
    "    print(f\"  - {var.variable_id}: {var.long_name}\")\n",
    "    print(f\"    Units: {var.units}\")\n",
    "    print(f\"    Frequency: {var.frequency}\")\n",
    "    print(f\"    Dimensions: {var.dimensions}\")\n",
    "    print()\n",
    "\n",
    "# Show other available properties that can be interrogated\n",
    "available_props = cmip6_dataset.get_props(\"__available__\")\n",
    "print(f\"üîß Other Available Properties:\")\n",
    "print(f\"Available props: {', '.join(available_props)}\")\n",
    "print(f\"Use cmip6_dataset.get_props('property_name') to explore any of these:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecbc490",
   "metadata": {},
   "source": [
    "## 5. Filter and Subset Data\n",
    "\n",
    "Apply filters to select specific climate model, experiment, variable, and spatial/temporal subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "733578f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Applying selection criteria:\n",
      "  model: CESM2\n",
      "  experiment: ssp585\n",
      "  variable: tas\n",
      "  frequency: monthly\n",
      "  spatial_bounds: {'lat': [30, 70], 'lon': [-130, -60]}\n",
      "  temporal_bounds: {'start': '2020-01-01', 'end': '2050-12-31'}\n",
      "\n",
      "üîÑ Filtering dataset...\n",
      "‚úÖ Filtered dataset created!\n",
      "Original size: 1250.0 GB\n",
      "Filtered size: 85.2 GB\n",
      "Reduction: 93.2%\n",
      "\n",
      "üìã Filtered Dataset Structure:\n",
      "Variables: ['tas']\n",
      "Spatial shape: (40, 70)\n",
      "Temporal shape: (372,)\n",
      "Total timesteps: 372\n",
      "Data format: xarray\n"
     ]
    }
   ],
   "source": [
    "# Define our selection criteria\n",
    "selection_criteria = {\n",
    "    'model': 'CESM2',  # Community Earth System Model\n",
    "    'experiment': 'ssp585',  # High emissions scenario\n",
    "    'variable': 'tas',  # Near-surface air temperature\n",
    "    'frequency': 'monthly',\n",
    "    'spatial_bounds': {\n",
    "        'lat': [30, 70],  # Northern hemisphere focus\n",
    "        'lon': [-130, -60]  # North America\n",
    "    },\n",
    "    'temporal_bounds': {\n",
    "        'start': '2020-01-01',\n",
    "        'end': '2050-12-31'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"üéØ Applying selection criteria:\")\n",
    "for key, value in selection_criteria.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Apply the filters using GeoCroissant's filtering API\n",
    "print(\"\\nüîÑ Filtering dataset...\")\n",
    "filtered_dataset = cmip6_dataset.filter(**selection_criteria)\n",
    "\n",
    "print(f\"‚úÖ Filtered dataset created!\")\n",
    "print(f\"Original size: {cmip6_dataset.estimated_size_gb:.1f} GB\")\n",
    "print(f\"Filtered size: {filtered_dataset.estimated_size_gb:.1f} GB\")\n",
    "print(f\"Reduction: {(1 - filtered_dataset.estimated_size_gb/cmip6_dataset.estimated_size_gb)*100:.1f}%\")\n",
    "\n",
    "# Show the structure of the filtered dataset\n",
    "print(f\"\\nüìã Filtered Dataset Structure:\")\n",
    "print(f\"Variables: {filtered_dataset.variables}\")\n",
    "print(f\"Spatial shape: {filtered_dataset.spatial_shape}\")\n",
    "print(f\"Temporal shape: {filtered_dataset.temporal_shape}\")\n",
    "print(f\"Total timesteps: {filtered_dataset.n_timesteps}\")\n",
    "print(f\"Data format: {filtered_dataset.data_format}\")  # xarray or tensor ready"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f979564d",
   "metadata": {},
   "source": [
    "## 6. Create PyTorch Dataset\n",
    "\n",
    "Convert the filtered climate data into a PyTorch Dataset for machine learning applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "819e213b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ PyTorch Dataset created!\n",
      "Dataset length: 360\n",
      "Sample shape: (1, 12, 40, 70)\n",
      "Target shape: (12, 40, 70)\n",
      "Data type: float32\n",
      "\n",
      "üì¶ DataLoader created with batch size 4\n",
      "Number of batches: 90\n",
      "\n",
      "Batch shapes:\n",
      "Features: (4, 1, 12, 40, 70)\n",
      "Targets: (4, 12, 40, 70)\n",
      "Features range: [-4.110, 4.534]\n",
      "Targets range: [-4.498, 4.450]\n"
     ]
    }
   ],
   "source": [
    "# Convert to PyTorch Dataset using GeoCroissant's ML integration\n",
    "climate_dataset = filtered_dataset.to_pytorch_dataset(\n",
    "    target_variable='tas',  # Temperature as target\n",
    "    feature_variables=['tas'],  # Using same variable for demo (can add more)\n",
    "    sequence_length=12,  # 12-month sequences\n",
    "    stride=1,  # Monthly stride\n",
    "    normalize=True,  # Apply standardization\n",
    "    transform='spatiotemporal'  # Prepare for spatiotemporal ML\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ PyTorch Dataset created!\")\n",
    "print(f\"Dataset length: {len(climate_dataset)}\")\n",
    "print(f\"Sample shape: {climate_dataset[0][0].shape}\")  # [features, time, lat, lon]\n",
    "print(f\"Target shape: {climate_dataset[0][1].shape}\")  # [time, lat, lon]\n",
    "print(f\"Data type: {climate_dataset[0][0].dtype}\")\n",
    "\n",
    "# Create DataLoader for training\n",
    "batch_size = 4\n",
    "train_loader = DataLoader(\n",
    "    climate_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "print(f\"\\nüì¶ DataLoader created with batch size {batch_size}\")\n",
    "print(f\"Number of batches: {len(train_loader)}\")\n",
    "\n",
    "# Inspect a batch\n",
    "sample_batch = next(iter(train_loader))\n",
    "features, targets = sample_batch\n",
    "print(f\"\\nBatch shapes:\")\n",
    "print(f\"Features: {features.shape}\")  # [batch, features, time, lat, lon]\n",
    "print(f\"Targets: {targets.shape}\")    # [batch, time, lat, lon]\n",
    "print(f\"Features range: [{features.min():.3f}, {features.max():.3f}]\")\n",
    "print(f\"Targets range: [{targets.min():.3f}, {targets.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626ca916",
   "metadata": {},
   "source": [
    "## 7. ML Training Simulation\n",
    "\n",
    "Demonstrate how to use the climate dataset in a machine learning training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d62556b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add missing torch methods for the training demo\n",
    "torch.device = lambda x: 'cpu'  # Mock device\n",
    "torch.cuda = type('cuda', (), {'is_available': lambda: False})()  # Mock CUDA\n",
    "\n",
    "# Define a simple CNN model for climate prediction\n",
    "class ClimateCNNModel(nn.Module):\n",
    "    def __init__(self, input_channels=1, hidden_dim=64):\n",
    "        super(ClimateCNNModel, self).__init__()\n",
    "        # Mock layers - would normally be actual PyTorch layers\n",
    "        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.lstm = nn.LSTM(64, hidden_dim, batch_first=True)\n",
    "        self.output_layer = nn.Linear(hidden_dim, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Mock forward pass - just return input reshaped\n",
    "        batch_size = x.shape[0]\n",
    "        return MockTorch.Tensor(np.random.randn(batch_size, 12, 40, 70))\n",
    "    \n",
    "    def to(self, device):\n",
    "        return self  # Mock .to() method\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ClimateCNNModel(input_channels=1).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(f\"‚úÖ Model initialized on device: {device}\")\n",
    "print(f\"Model architecture: ClimateCNNModel\")\n",
    "print(f\"Loss function: MSE Loss\")\n",
    "print(f\"Optimizer: Adam (lr=0.001)\")\n",
    "\n",
    "# Simulate training loop\n",
    "print(f\"\\n Starting training simulation...\")\n",
    "n_epochs = 3\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    n_batches = 0\n",
    "    \n",
    "    # Simulate training over a few batches\n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "        if batch_idx >= 3:  # Just simulate 3 batches per epoch\n",
    "            break\n",
    "            \n",
    "        # Mock training step\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass (mock)\n",
    "        predictions = model(features)\n",
    "        loss = criterion(predictions, targets)\n",
    "        \n",
    "        # Mock backward pass\n",
    "        # loss.backward()  # Would normally do backprop\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.min()  # Use min as mock loss value\n",
    "        n_batches += 1\n",
    "    \n",
    "    avg_loss = epoch_loss / n_batches if n_batches > 0 else 0\n",
    "    train_losses.append(avg_loss)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{n_epochs} - Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Training simulation completed!\")\n",
    "print(f\"Final training loss: {train_losses[-1]:.4f}\")\n",
    "print(f\"Model ready for climate prediction tasks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f298153d",
   "metadata": {},
   "source": [
    "## 8. Visualize Single Variable Layer\n",
    "\n",
    "Extract and visualize a single layer of climate data using the GeoCroissant visualization tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315d5195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract a specific time slice for visualization\n",
    "print(\"üé® Extracting data for visualization...\")\n",
    "\n",
    "# Get a single timestep from the original xarray data\n",
    "sample_data = filtered_dataset.to_xarray().isel(time=0)  # First timestep\n",
    "temperature_data = sample_data.tas  # Temperature variable\n",
    "\n",
    "# Create the visualization\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "# Plot the temperature data\n",
    "im = ax.contourf(\n",
    "    temperature_data.lon, \n",
    "    temperature_data.lat, \n",
    "    temperature_data.values,\n",
    "    levels=20,\n",
    "    cmap='RdYlBu_r',\n",
    "    transform=ccrs.PlateCarree()\n",
    ")\n",
    "\n",
    "# Add geographic features\n",
    "ax.add_feature(cfeature.COASTLINE, linewidth=0.5)\n",
    "ax.add_feature(cfeature.BORDERS, linewidth=0.3)\n",
    "ax.add_feature(cfeature.OCEAN, color='lightblue', alpha=0.3)\n",
    "ax.add_feature(cfeature.LAND, color='lightgray', alpha=0.3)\n",
    "\n",
    "# Add gridlines\n",
    "gl = ax.gridlines(draw_labels=True, dms=True, x_inline=False, y_inline=False)\n",
    "gl.top_labels = False\n",
    "gl.right_labels = False\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(im, ax=ax, shrink=0.7, pad=0.02)\n",
    "cbar.set_label('Temperature (K)', rotation=270, labelpad=15)\n",
    "\n",
    "# Set title and labels\n",
    "plt.title(f'CMIP6 Surface Temperature - {sample_data.time.dt.strftime(\"%Y-%m\").values}\\\\n'\n",
    "          f'Model: CESM2, Experiment: SSP5-8.5', fontsize=14, pad=20)\n",
    "\n",
    "# Set extent to match our filtered region\n",
    "ax.set_extent([-130, -60, 30, 70], crs=ccrs.PlateCarree())\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show data statistics\n",
    "print(f\"\\\\nüìä Data Statistics:\")\n",
    "print(f\"Temperature range: {temperature_data.min().values:.1f}K to {temperature_data.max().values:.1f}K\")\n",
    "print(f\"Mean temperature: {temperature_data.mean().values:.1f}K\")\n",
    "print(f\"Spatial resolution: {abs(temperature_data.lat.diff('lat').mean().values):.3f}¬∞ lat x {abs(temperature_data.lon.diff('lon').mean().values):.3f}¬∞ lon\")\n",
    "print(f\"Grid points: {len(temperature_data.lat)} lat x {len(temperature_data.lon)} lon\")\n",
    "print(f\"Date: {sample_data.time.dt.strftime('%Y-%m-%d').values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50dcda8",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the complete workflow for using **GeoCroissant** with CMIP6 environmental datasets:\n",
    "\n",
    "### Key Capabilities Shown:\n",
    "1. **üîç Dataset Discovery**: Search across multiple climate data repositories\n",
    "2. **üì¶ Easy Loading**: Load CMIP6 datasets with STAC integration  \n",
    "3. **üîç Deep Interrogation**: Explore models, experiments, variables, and metadata\n",
    "4. **üéØ Smart Filtering**: Apply complex spatial, temporal, and variable filters\n",
    "5. **ü§ñ ML Integration**: Convert to PyTorch datasets for training\n",
    "6. **üèÉ‚Äç‚ôÇÔ∏è Training Ready**: Use in actual ML training pipelines\n",
    "7. **üé® Visualization**: Plot geospatial climate data with cartographic projections\n",
    "\n",
    "### Next Steps:\n",
    "- **Implement** the actual GeoCroissant library and extensions\n",
    "- **Integrate** with real STAC catalogs (CEDA, ESGF, etc.)\n",
    "- **Add** more sophisticated ML dataset transformations\n",
    "- **Extend** to other environmental datasets (ERA5, satellite data, etc.)\n",
    "- **Optimize** for large-scale distributed computing\n",
    "\n",
    "> This mockup provides a clear vision for how environmental scientists and ML researchers could seamlessly work with massive climate datasets! üåç"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
