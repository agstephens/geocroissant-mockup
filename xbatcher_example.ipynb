{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a70ad58",
   "metadata": {},
   "source": [
    "## Xarray to Pytorch loader example\n",
    "\n",
    "Brief example based on xbatcher and xarray into pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66433f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nerc_eds.apis import loader_api\n",
    "# Can use datapoint under the hood?\n",
    "\n",
    "xbatcher_kwargs = {}\n",
    "\n",
    "# loader_api backed by geocroissant/STAC for searching data?\n",
    "search = loader_api.search(\n",
    "    keywords=[\"climate\", \"CMIP6\", \"temperature\", \"precipitation\"],\n",
    "    spatial_coverage=\"global\",\n",
    "    temporal_range=(\"2015-01-01\", \"2100-12-31\")\n",
    ")\n",
    "\n",
    "# Load_dataset uses code from below to create xbatcher dataset\n",
    "xb_dataset = search.load_dataset(\n",
    "    **xbatcher_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a04236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example xbatcher (behind the scenes)\n",
    "# https://xbatcher.readthedocs.io/en/latest/user-guide/training-a-neural-network-with-Pytorch-and-xbatcher.html\n",
    "import xarray as xr\n",
    "import xbatcher as xb\n",
    "import xbatcher.loaders.torch\n",
    "\n",
    "ds = xr.open_dataset(\n",
    "    's3://carbonplan-share/xbatcher/fashion-mnist-train.zarr',\n",
    "    engine='zarr',\n",
    "    chunks={},\n",
    "    backend_kwargs={'storage_options': {'anon': True}},\n",
    ")\n",
    "\n",
    "# Define batch generators\n",
    "X_bgen = xb.BatchGenerator(\n",
    "    ds['variable'],\n",
    "    input_dims={'time':ds.time.size, 'lat':ds.lat.size, 'lon': ds.lon.size},\n",
    "    preload_batch=False,\n",
    ")\n",
    "y_bgen = xb.BatchGenerator(\n",
    "    ds['labels'], input_dims={'sample': 2000}, preload_batch=False\n",
    ")\n",
    "\n",
    "xb_dataset = xbatcher.loaders.torch.MapDataset(X_bgen, y_bgen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a16194e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Xbatcher to pytorch\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    xb_dataset,\n",
    "    batch_size=None,  # Using batches defined by the dataset itself (via xbatcher)\n",
    "    prefetch_factor=3,  # Prefetch up to 3 batches in advance to reduce data loading latency\n",
    "    num_workers=4,  # Use 4 parallel worker processes to load data concurrently\n",
    "    persistent_workers=True,  # Keep workers alive between epochs for faster subsequent epochs\n",
    "    multiprocessing_context='forkserver',  # Use \"forkserver\" to spawn subprocesses, ensuring stability in multiprocessing\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
